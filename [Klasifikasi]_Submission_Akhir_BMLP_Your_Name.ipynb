{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "fKADPWcFKlj3"
      },
      "source": [
        "# **1. Import Library**"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "LgA3ERnVn84N"
      },
      "source": [
        "Pada tahap ini, Anda perlu mengimpor beberapa pustaka (library) Python yang dibutuhkan untuk analisis data dan pembangunan model machine learning."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "metadata": {
        "id": "BlmvjLY9M4Yj"
      },
      "outputs": [],
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "import seaborn as sns\n",
        "import matplotlib.pyplot as plt\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.preprocessing import LabelEncoder, StandardScaler, MinMaxScaler\n",
        "from sklearn.neighbors import KNeighborsClassifier\n",
        "from sklearn.tree import DecisionTreeClassifier\n",
        "from sklearn.ensemble import RandomForestClassifier\n",
        "from sklearn.svm import SVC\n",
        "from sklearn.naive_bayes import GaussianNB\n",
        "from sklearn.metrics import confusion_matrix, accuracy_score, precision_score, recall_score, f1_score"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "f3YIEnAFKrKL"
      },
      "source": [
        "# **2. Memuat Dataset dari Hasil Clustering**"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Ey3ItwTen_7E"
      },
      "source": [
        "Memuat dataset hasil clustering dari file CSV ke dalam variabel DataFrame."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 18,
      "metadata": {
        "id": "GHCGNTyrM5fS"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "<class 'pandas.core.frame.DataFrame'>\n",
            "RangeIndex: 2512 entries, 0 to 2511\n",
            "Data columns (total 21 columns):\n",
            " #   Column                   Non-Null Count  Dtype  \n",
            "---  ------                   --------------  -----  \n",
            " 0   TransactionID            2512 non-null   object \n",
            " 1   AccountID                2512 non-null   object \n",
            " 2   TransactionAmount        2512 non-null   float64\n",
            " 3   TransactionDate          2512 non-null   object \n",
            " 4   TransactionType          2512 non-null   object \n",
            " 5   Location                 2512 non-null   object \n",
            " 6   DeviceID                 2512 non-null   object \n",
            " 7   IP Address               2512 non-null   object \n",
            " 8   MerchantID               2512 non-null   object \n",
            " 9   Channel                  2512 non-null   object \n",
            " 10  CustomerAge              2512 non-null   int64  \n",
            " 11  CustomerOccupation       2512 non-null   object \n",
            " 12  TransactionDuration      2512 non-null   int64  \n",
            " 13  LoginAttempts            2512 non-null   int64  \n",
            " 14  AccountBalance           2512 non-null   float64\n",
            " 15  PreviousTransactionDate  2512 non-null   object \n",
            " 16  dbscanCluster            2512 non-null   int64  \n",
            " 17  DBSCAN_Cluster           2512 non-null   object \n",
            " 18  DBSCAN_Fraud             2512 non-null   object \n",
            " 19  PCA_1                    2512 non-null   float64\n",
            " 20  PCA_2                    2512 non-null   float64\n",
            "dtypes: float64(4), int64(4), object(13)\n",
            "memory usage: 412.3+ KB\n"
          ]
        }
      ],
      "source": [
        "df = pd.read_csv(\"bfdetection.csv\")\n",
        "df.head()\n",
        "df.info()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "KkPem5eWL2UP"
      },
      "source": [
        "# **3. Data Splitting**"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "YYj1rl_JNI9Y"
      },
      "source": [
        "Tahap Data Splitting bertujuan untuk memisahkan dataset menjadi dua bagian: data latih (training set) dan data uji (test set)."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 19,
      "metadata": {
        "id": "OubAW-7ONKVj"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Index(['TransactionID', 'AccountID', 'TransactionAmount', 'TransactionDate',\n",
            "       'TransactionType', 'Location', 'DeviceID', 'IP Address', 'MerchantID',\n",
            "       'Channel', 'CustomerAge', 'CustomerOccupation', 'TransactionDuration',\n",
            "       'LoginAttempts', 'AccountBalance', 'PreviousTransactionDate',\n",
            "       'dbscanCluster', 'DBSCAN_Cluster', 'DBSCAN_Fraud', 'PCA_1', 'PCA_2'],\n",
            "      dtype='object')\n",
            "Jumlah data latih: 2009, Jumlah data uji: 503\n"
          ]
        }
      ],
      "source": [
        "print(df.columns)\n",
        "df['TransactionID'] = df['TransactionID'].fillna(0)\n",
        "df = df.dropna(subset=['TransactionID'])\n",
        "X = df.drop(columns=['AccountID'])  \n",
        "y = df['AccountID'] \n",
        "Xlatih, Xuji, ylatih, yuji = train_test_split(X, y, test_size=0.2, random_state=42)\n",
        "print(f\"Jumlah data latih: {Xlatih.shape[0]}, Jumlah data uji: {Xuji.shape[0]}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "IVPbB03CMhTT"
      },
      "source": [
        "# **4. Membangun Model Klasifikasi**\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Ned1pL9zMmBK"
      },
      "source": [
        "## **a. Membangun Model Klasifikasi**"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "WAWzPOE4Nkti"
      },
      "source": [
        "Setelah memilih algoritma klasifikasi yang sesuai, langkah selanjutnya adalah melatih model menggunakan data latih.\n",
        "\n",
        "Berikut adalah rekomendasi tahapannya.\n",
        "1. Pilih algoritma klasifikasi yang sesuai, seperti Logistic Regression, Decision Tree, Random Forest, atau K-Nearest Neighbors (KNN).\n",
        "2. Latih model menggunakan data latih."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 20,
      "metadata": {
        "id": "4JYxBe87NLDk"
      },
      "outputs": [
        {
          "ename": "ValueError",
          "evalue": "could not convert string to float: 'TX001627'",
          "output_type": "error",
          "traceback": [
            "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
            "\u001b[31mValueError\u001b[39m                                Traceback (most recent call last)",
            "\u001b[32m~\\AppData\\Local\\Temp\\ipykernel_12632\\999594458.py\u001b[39m in \u001b[36m?\u001b[39m\u001b[34m()\u001b[39m\n\u001b[32m----> \u001b[39m\u001b[32m1\u001b[39m knn = KNeighborsClassifier().fit(Xlatih, ylatih)\n\u001b[32m      2\u001b[39m dt = DecisionTreeClassifier().fit(Xlatih, ylatih)\n\u001b[32m      3\u001b[39m rf = RandomForestClassifier().fit(Xlatih, ylatih)\n\u001b[32m      4\u001b[39m svm = SVC().fit(Xlatih, ylatih)\n",
            "\u001b[32mc:\\Users\\ASUS\\AppData\\Local\\Programs\\Python\\Python313\\Lib\\site-packages\\sklearn\\base.py\u001b[39m in \u001b[36m?\u001b[39m\u001b[34m(estimator, *args, **kwargs)\u001b[39m\n\u001b[32m   1385\u001b[39m                 skip_parameter_validation=(\n\u001b[32m   1386\u001b[39m                     prefer_skip_nested_validation \u001b[38;5;28;01mor\u001b[39;00m global_skip_validation\n\u001b[32m   1387\u001b[39m                 )\n\u001b[32m   1388\u001b[39m             ):\n\u001b[32m-> \u001b[39m\u001b[32m1389\u001b[39m                 \u001b[38;5;28;01mreturn\u001b[39;00m fit_method(estimator, *args, **kwargs)\n",
            "\u001b[32mc:\\Users\\ASUS\\AppData\\Local\\Programs\\Python\\Python313\\Lib\\site-packages\\sklearn\\neighbors\\_classification.py\u001b[39m in \u001b[36m?\u001b[39m\u001b[34m(self, X, y)\u001b[39m\n\u001b[32m    235\u001b[39m         -------\n\u001b[32m    236\u001b[39m         self : KNeighborsClassifier\n\u001b[32m    237\u001b[39m             The fitted k-nearest neighbors classifier.\n\u001b[32m    238\u001b[39m         \"\"\"\n\u001b[32m--> \u001b[39m\u001b[32m239\u001b[39m         \u001b[38;5;28;01mreturn\u001b[39;00m self._fit(X, y)\n",
            "\u001b[32mc:\\Users\\ASUS\\AppData\\Local\\Programs\\Python\\Python313\\Lib\\site-packages\\sklearn\\neighbors\\_base.py\u001b[39m in \u001b[36m?\u001b[39m\u001b[34m(self, X, y)\u001b[39m\n\u001b[32m    474\u001b[39m     \u001b[38;5;28;01mdef\u001b[39;00m _fit(self, X, y=\u001b[38;5;28;01mNone\u001b[39;00m):\n\u001b[32m    475\u001b[39m         ensure_all_finite = \u001b[33m\"allow-nan\"\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m get_tags(self).input_tags.allow_nan \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;28;01mTrue\u001b[39;00m\n\u001b[32m    476\u001b[39m         \u001b[38;5;28;01mif\u001b[39;00m self.__sklearn_tags__().target_tags.required:\n\u001b[32m    477\u001b[39m             \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28;01mnot\u001b[39;00m isinstance(X, (KDTree, BallTree, NeighborsBase)):\n\u001b[32m--> \u001b[39m\u001b[32m478\u001b[39m                 X, y = validate_data(\n\u001b[32m    479\u001b[39m                     self,\n\u001b[32m    480\u001b[39m                     X,\n\u001b[32m    481\u001b[39m                     y,\n",
            "\u001b[32mc:\\Users\\ASUS\\AppData\\Local\\Programs\\Python\\Python313\\Lib\\site-packages\\sklearn\\utils\\validation.py\u001b[39m in \u001b[36m?\u001b[39m\u001b[34m(_estimator, X, y, reset, validate_separately, skip_check_array, **check_params)\u001b[39m\n\u001b[32m   2957\u001b[39m             \u001b[38;5;28;01mif\u001b[39;00m \u001b[33m\"estimator\"\u001b[39m \u001b[38;5;28;01mnot\u001b[39;00m \u001b[38;5;28;01min\u001b[39;00m check_y_params:\n\u001b[32m   2958\u001b[39m                 check_y_params = {**default_check_params, **check_y_params}\n\u001b[32m   2959\u001b[39m             y = check_array(y, input_name=\u001b[33m\"y\"\u001b[39m, **check_y_params)\n\u001b[32m   2960\u001b[39m         \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m-> \u001b[39m\u001b[32m2961\u001b[39m             X, y = check_X_y(X, y, **check_params)\n\u001b[32m   2962\u001b[39m         out = X, y\n\u001b[32m   2963\u001b[39m \n\u001b[32m   2964\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28;01mnot\u001b[39;00m no_val_X \u001b[38;5;28;01mand\u001b[39;00m check_params.get(\u001b[33m\"ensure_2d\"\u001b[39m, \u001b[38;5;28;01mTrue\u001b[39;00m):\n",
            "\u001b[32mc:\\Users\\ASUS\\AppData\\Local\\Programs\\Python\\Python313\\Lib\\site-packages\\sklearn\\utils\\validation.py\u001b[39m in \u001b[36m?\u001b[39m\u001b[34m(X, y, accept_sparse, accept_large_sparse, dtype, order, copy, force_writeable, force_all_finite, ensure_all_finite, ensure_2d, allow_nd, multi_output, ensure_min_samples, ensure_min_features, y_numeric, estimator)\u001b[39m\n\u001b[32m   1366\u001b[39m         )\n\u001b[32m   1367\u001b[39m \n\u001b[32m   1368\u001b[39m     ensure_all_finite = _deprecate_force_all_finite(force_all_finite, ensure_all_finite)\n\u001b[32m   1369\u001b[39m \n\u001b[32m-> \u001b[39m\u001b[32m1370\u001b[39m     X = check_array(\n\u001b[32m   1371\u001b[39m         X,\n\u001b[32m   1372\u001b[39m         accept_sparse=accept_sparse,\n\u001b[32m   1373\u001b[39m         accept_large_sparse=accept_large_sparse,\n",
            "\u001b[32mc:\\Users\\ASUS\\AppData\\Local\\Programs\\Python\\Python313\\Lib\\site-packages\\sklearn\\utils\\validation.py\u001b[39m in \u001b[36m?\u001b[39m\u001b[34m(array, accept_sparse, accept_large_sparse, dtype, order, copy, force_writeable, force_all_finite, ensure_all_finite, ensure_non_negative, ensure_2d, allow_nd, ensure_min_samples, ensure_min_features, estimator, input_name)\u001b[39m\n\u001b[32m   1052\u001b[39m                         )\n\u001b[32m   1053\u001b[39m                     array = xp.astype(array, dtype, copy=\u001b[38;5;28;01mFalse\u001b[39;00m)\n\u001b[32m   1054\u001b[39m                 \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m   1055\u001b[39m                     array = _asarray_with_order(array, order=order, dtype=dtype, xp=xp)\n\u001b[32m-> \u001b[39m\u001b[32m1056\u001b[39m             \u001b[38;5;28;01mexcept\u001b[39;00m ComplexWarning \u001b[38;5;28;01mas\u001b[39;00m complex_warning:\n\u001b[32m   1057\u001b[39m                 raise ValueError(\n\u001b[32m   1058\u001b[39m                     \u001b[33m\"Complex data not supported\\n{}\\n\"\u001b[39m.format(array)\n\u001b[32m   1059\u001b[39m                 ) \u001b[38;5;28;01mfrom\u001b[39;00m complex_warning\n",
            "\u001b[32mc:\\Users\\ASUS\\AppData\\Local\\Programs\\Python\\Python313\\Lib\\site-packages\\sklearn\\utils\\_array_api.py\u001b[39m in \u001b[36m?\u001b[39m\u001b[34m(array, dtype, order, copy, xp, device)\u001b[39m\n\u001b[32m    835\u001b[39m         \u001b[38;5;66;03m# Use NumPy API to support order\u001b[39;00m\n\u001b[32m    836\u001b[39m         \u001b[38;5;28;01mif\u001b[39;00m copy \u001b[38;5;28;01mis\u001b[39;00m \u001b[38;5;28;01mTrue\u001b[39;00m:\n\u001b[32m    837\u001b[39m             array = numpy.array(array, order=order, dtype=dtype)\n\u001b[32m    838\u001b[39m         \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m--> \u001b[39m\u001b[32m839\u001b[39m             array = numpy.asarray(array, order=order, dtype=dtype)\n\u001b[32m    840\u001b[39m \n\u001b[32m    841\u001b[39m         \u001b[38;5;66;03m# At this point array is a NumPy ndarray. We convert it to an array\u001b[39;00m\n\u001b[32m    842\u001b[39m         \u001b[38;5;66;03m# container that is consistent with the input's namespace.\u001b[39;00m\n",
            "\u001b[32mc:\\Users\\ASUS\\AppData\\Local\\Programs\\Python\\Python313\\Lib\\site-packages\\pandas\\core\\generic.py\u001b[39m in \u001b[36m?\u001b[39m\u001b[34m(self, dtype, copy)\u001b[39m\n\u001b[32m   2149\u001b[39m     def __array__(\n\u001b[32m   2150\u001b[39m         self, dtype: npt.DTypeLike | \u001b[38;5;28;01mNone\u001b[39;00m = \u001b[38;5;28;01mNone\u001b[39;00m, copy: bool_t | \u001b[38;5;28;01mNone\u001b[39;00m = \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[32m   2151\u001b[39m     ) -> np.ndarray:\n\u001b[32m   2152\u001b[39m         values = self._values\n\u001b[32m-> \u001b[39m\u001b[32m2153\u001b[39m         arr = np.asarray(values, dtype=dtype)\n\u001b[32m   2154\u001b[39m         if (\n\u001b[32m   2155\u001b[39m             astype_is_view(values.dtype, arr.dtype)\n\u001b[32m   2156\u001b[39m             \u001b[38;5;28;01mand\u001b[39;00m using_copy_on_write()\n",
            "\u001b[31mValueError\u001b[39m: could not convert string to float: 'TX001627'"
          ]
        }
      ],
      "source": [
        "knn = KNeighborsClassifier().fit(Xlatih, ylatih)\n",
        "dt = DecisionTreeClassifier().fit(Xlatih, ylatih)\n",
        "rf = RandomForestClassifier().fit(Xlatih, ylatih)\n",
        "svm = SVC().fit(Xlatih, ylatih)\n",
        "nb = GaussianNB().fit(Xlatih, ylatih)\n",
        " \n",
        "print(\"Model training selesai.\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "seYoHNY3XU1y"
      },
      "source": [
        "Tulis narasi atau penjelasan algoritma yang Anda gunakan."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ergzChZFEL-O"
      },
      "source": [
        "## **b. Evaluasi Model Klasifikasi**"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "zOm68u-7NpLT"
      },
      "source": [
        "Berikut adalah **rekomendasi** tahapannya.\n",
        "1. Lakukan prediksi menggunakan data uji.\n",
        "2. Hitung metrik evaluasi seperti Accuracy dan F1-Score (Opsional: Precision dan Recall).\n",
        "3. Buat confusion matrix untuk melihat detail prediksi benar dan salah."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "tMq4QAssNLip"
      },
      "outputs": [],
      "source": [
        "#Type your code here"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "H4_9OwrsXZlz"
      },
      "source": [
        "Tulis hasil evaluasi algoritma yang digunakan, jika Anda menggunakan 2 algoritma, maka bandingkan hasilnya."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ph9yIYDXEPuB"
      },
      "source": [
        "## **c. Tuning Model Klasifikasi (Optional)**"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-Bikx3LINv5e"
      },
      "source": [
        "Gunakan GridSearchCV, RandomizedSearchCV, atau metode lainnya untuk mencari kombinasi hyperparameter terbaik"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "winbFzb8NL95"
      },
      "outputs": [],
      "source": [
        "#Type your code here"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "hE7pqlEPEYzI"
      },
      "source": [
        "## **d. Evaluasi Model Klasifikasi setelah Tuning (Optional)**"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "feaPESoeN0zz"
      },
      "source": [
        "Berikut adalah rekomendasi tahapannya.\n",
        "1. Gunakan model dengan hyperparameter terbaik.\n",
        "2. Hitung ulang metrik evaluasi untuk melihat apakah ada peningkatan performa."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "HTXZRvEeNMb1"
      },
      "outputs": [],
      "source": [
        "#Type your code here"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ZRsOdm4uEgAW"
      },
      "source": [
        "## **e. Analisis Hasil Evaluasi Model Klasifikasi**"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Hm3BhSi6N4_l"
      },
      "source": [
        "Berikut adalah **rekomendasi** tahapannya.\n",
        "1. Bandingkan hasil evaluasi sebelum dan setelah tuning (jika dilakukan).\n",
        "2. Identifikasi kelemahan model, seperti:\n",
        "  - Precision atau Recall rendah untuk kelas tertentu.\n",
        "  - Apakah model mengalami overfitting atau underfitting?\n",
        "3. Berikan rekomendasi tindakan lanjutan, seperti mengumpulkan data tambahan atau mencoba algoritma lain jika hasil belum memuaskan."
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.13.2"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
